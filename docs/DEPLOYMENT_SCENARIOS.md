---
layout: default
title: Deployment Scenarios - AtlasP2P
---

# AtlasP2P - Complete Deployment Scenarios

## üéØ All Possible Scenarios Explained

This document covers **EVERY** way you can deploy AtlasP2P, from development to production.

---

## üìä Scenario Matrix

| Scenario | Supabase | Containers | Use Case | Cost |
|----------|----------|------------|----------|------|
| **Dev: Docker** | Local (Docker) | All services | Local development | $0 |
| **Dev: Cloud** | Supabase Cloud | Web + Crawler | Cloud development | $0-25/mo |
| **Dev: Bare** | Local (Docker) | None (pnpm dev) | Frontend dev only | $0 |
| **Prod: Docker** | Local (Docker) | All services | Self-hosted VPS | $15-25/mo |
| **Prod: Cloud** | Supabase Cloud | Web + Crawler | Hybrid cloud | $40-50/mo |
| **Prod: Serverless** | Supabase Cloud | None (Vercel) | Fully serverless | $50-100/mo |

---

## ü§ñ Automated CI/CD

**AtlasP2P includes a complete CI/CD pipeline for automated production deployments.**

- Auto-detects infrastructure (Caddy, secrets management)
- Builds and deploys on push to master
- Health checks with automatic rollback
- Multiple secrets sources (AWS SSM, GitHub Secrets, manual)

**Setup:** Configure once in `config/project.config.yaml`, deploy forever.

**See:** [CI/CD Documentation](./CICD.md) for complete guide.

---

## üîç Detailed Scenarios

### Scenario 1: Dev - Local Docker (Default)

**Architecture:**
```
Docker Compose
‚îú‚îÄ‚îÄ PostgreSQL (5432 ‚Üí ${DB_PORT:-4021})
‚îú‚îÄ‚îÄ Kong (8000 ‚Üí ${KONG_PORT:-4020})
‚îú‚îÄ‚îÄ GoTrue (auth)
‚îú‚îÄ‚îÄ PostgREST (REST API)
‚îú‚îÄ‚îÄ Inbucket (email testing ‚Üí ${INBUCKET_WEB_PORT:-4023})
‚îú‚îÄ‚îÄ Supabase Studio (admin ‚Üí ${STUDIO_PORT:-4022})
‚îú‚îÄ‚îÄ Web App (Next.js ‚Üí ${WEB_PORT:-4000})
‚îî‚îÄ‚îÄ Crawler (Python)
```

**Port Configuration:**
All exposed ports are configurable via `.env` for maximum flexibility:

```bash
# .env - Port Configuration
WEB_PORT=4000              # Web app
KONG_PORT=4020             # Supabase API Gateway
DB_PORT=4021               # PostgreSQL direct access
STUDIO_PORT=4022           # Supabase Studio UI
INBUCKET_WEB_PORT=4023     # Email testing UI
INBUCKET_SMTP_PORT=4024    # Email SMTP
```

**Why configurable ports?**
- Run multiple AtlasP2P instances (different chains)
- Avoid port conflicts with existing services
- Custom firewall rules
- Fork-friendly deployment

**Setup:**
```bash
make setup-docker
make docker-dev
```

**Environment (.env):**
```bash
NEXT_PUBLIC_SUPABASE_URL=http://localhost:4020
SUPABASE_INTERNAL_URL=http://kong:8000  # Docker internal
```

**Migrations:** Auto-run from `/docker-entrypoint-initdb.d/`

**Storage:** Docker volume `avatar-storage`

**When to use:**
- First time trying AtlasP2P
- Full control over entire stack
- Offline development
- Testing database changes

---

### Scenario 2: Dev - Cloud Supabase

**Architecture:**
```
Supabase Cloud (managed)
  ‚Üë
Docker Compose (local)
‚îú‚îÄ‚îÄ Web App (Next.js ‚Üí 4000)
‚îî‚îÄ‚îÄ Crawler (Python)
```

**Setup:**
```bash
# 1. Create Supabase project
supabase projects create my-nodes

# 2. Setup locally
make setup-cloud
nano .env  # Add Supabase credentials

# 3. Run migrations
supabase link && supabase db push

# 4. Start
make cloud-dev
```

**Environment (.env):**
```bash
NEXT_PUBLIC_SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_INTERNAL_URL=https://xxxxx.supabase.co  # Same URL
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJ...
SUPABASE_SERVICE_ROLE_KEY=eyJ...
```

**Migrations:** `supabase db push` or SQL Editor

**Storage:** Supabase Storage with CDN

**When to use:**
- Want managed database
- Testing Supabase features
- Global CDN for avatars
- Preparing for production

**Cost:**
- Free tier: 500MB DB, 2GB bandwidth
- Pro: $25/mo (8GB DB, 250GB bandwidth)

---

### Scenario 3: Dev - Bare Metal (Frontend Only)

**Architecture:**
```
Docker Compose (background)
‚îú‚îÄ‚îÄ PostgreSQL
‚îú‚îÄ‚îÄ Kong
‚îî‚îÄ‚îÄ Auth services

Terminal (foreground)
‚îî‚îÄ‚îÄ pnpm dev (Next.js only)
```

**Setup:**
```bash
# 1. Start database services (in background)
make docker-dev  # Starts all services
# OR manually start only DB + Supabase services:
# docker compose -f docker-compose.yml up -d db kong auth rest meta

# 2. Run migrations
make migrate

# 3. Start Next.js in dev mode (foreground, hot reload)
pnpm --filter @atlasp2p/web dev
```

**When to use:**
- Frontend development only
- Don't need hot reload in Docker
- Faster iteration on UI
- Debugging Next.js server

---

### Scenario 4: Prod - Self-Hosted (Full Docker)

**Architecture:**
```
Internet
  ‚Üì
Caddy (80/443) ‚Üê Auto-SSL
  ‚Üì
Docker Compose
‚îú‚îÄ‚îÄ PostgreSQL (internal only)
‚îú‚îÄ‚îÄ Kong (internal only)
‚îú‚îÄ‚îÄ Auth services
‚îú‚îÄ‚îÄ Web App (internal only)
‚îî‚îÄ‚îÄ Crawler
```

**Setup (Manual):**
```bash
# On production server
git clone https://github.com/YourOrg/YourNodes.git
cd YourNodes

cp .env.docker.example .env
nano .env

# Required:
DOMAIN=nodes.dogecoin.com
ACME_EMAIL=admin@dogecoin.com
SMTP_HOST=smtp.sendgrid.net
SMTP_PORT=587
SMTP_USER=apikey
SMTP_PASS=your-key

# Start (with container Caddy)
make prod-docker

# OR start without container Caddy (if host Caddy already installed)
# See "Host Caddy Setup" below for one-time configuration
make prod-docker-no-caddy
```

**Host Caddy Setup (One-Time, Manual):**

If using `make prod-docker-no-caddy`, you must configure host Caddy first:

```bash
# 1. Copy and customize the template
cp docker/Caddyfile.host.example /tmp/nodesmap.Caddyfile

# 2. Edit with your actual values (from .env):
#    - SITE_URL ‚Üí nodes.yourchain.com
#    - API_EXTERNAL_URL ‚Üí api.nodes.yourchain.com
#    - WEB_PORT ‚Üí localhost:4000
#    - KONG_PORT ‚Üí localhost:4020
nano /tmp/nodesmap.Caddyfile

# 3. Deploy to server
sudo cp /tmp/nodesmap.Caddyfile /etc/caddy/sites/yourproject.Caddyfile
sudo chown root:root /etc/caddy/sites/yourproject.Caddyfile
sudo chmod 644 /etc/caddy/sites/yourproject.Caddyfile

# 4. Ensure main Caddyfile imports sites directory
# Add to /etc/caddy/Caddyfile if not already present:
#   import /etc/caddy/sites/*.Caddyfile

# 5. Reload Caddy
sudo systemctl reload caddy
sudo systemctl status caddy
```

**Note:** This is infrastructure config (like nginx), separate from app deployment.
CI/CD NEVER touches this file. If you change ports later, update both:
- AWS SSM Parameter Store (for deployments)
- /etc/caddy/sites/yourproject.Caddyfile (infrastructure)

See `docker/Caddyfile.host.example` for scenarios and troubleshooting.

**Setup (Automated CI/CD):**
```bash
# Configure deployment in config/project.config.yaml
# See docs/CICD.md for complete guide
# Then just push to master - automatic deployment!
```

**Includes:**
- Auto-SSL via Caddy (Let's Encrypt)
- All services containerized
- Automatic backups (setup required)
- Persistent volumes

**Server Requirements:**
- 2 CPU, 4GB RAM minimum
- 50GB SSD
- Ubuntu 22.04 or similar
- Docker + Docker Compose

**Cost:**
- DigitalOcean: $24/mo (4GB RAM)
- Hetzner: $12/mo (4GB RAM)
- Linode: $24/mo (4GB RAM)

**When to use:**
- Full control required
- Small-medium network (<5K nodes)
- Cost-sensitive deployment
- Don't want external dependencies

---

### Scenario 5: Prod - Hybrid Cloud

**Architecture:**
```
Internet
  ‚Üì
Caddy (80/443) ‚Üê Auto-SSL
  ‚Üì
Docker Compose
‚îú‚îÄ‚îÄ Web App
‚îî‚îÄ‚îÄ Crawler
  ‚Üì
Supabase Cloud (managed)
‚îú‚îÄ‚îÄ PostgreSQL
‚îú‚îÄ‚îÄ Auth
‚îú‚îÄ‚îÄ Storage
‚îî‚îÄ‚îÄ Realtime
```

**Setup (Manual):**
```bash
# 1. Create Supabase project
supabase projects create nodes-prod --org-id xxx --region us-east-1

# 2. On production server
git clone https://github.com/YourOrg/YourNodes.git
cd YourNodes

cp .env.cloud.example .env
nano .env

# Required:
NEXT_PUBLIC_SUPABASE_URL=https://xxxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJ...
SUPABASE_SERVICE_ROLE_KEY=eyJ...
DOMAIN=nodes.dogecoin.com
ACME_EMAIL=admin@dogecoin.com

# 3. Run migrations
supabase link --project-ref xxxxx
supabase db push

# 4. Create storage bucket (SQL Editor)
# See SUPABASE_QUICKSTART.md

# 5. Start (with Caddy)
make prod-cloud

# OR start without container Caddy
make prod-cloud-no-caddy
```

**Setup (Automated CI/CD):**
```bash
# Configure deployment in config/project.config.yaml
# Set mode: self-hosted-cloud
# See docs/CICD.md for complete guide
```

**Benefits:**
- Managed database (auto-backups, scaling)
- CDN-delivered avatars
- Less server resources needed
- Professional monitoring

**Server Requirements:**
- 1 CPU, 2GB RAM sufficient
- 20GB SSD
- Lower specs than full Docker

**Cost:**
- VPS: $12/mo (2GB RAM)
- Supabase Pro: $25/mo
- Total: ~$37/mo

**When to use:**
- Medium-large network (5K+ nodes)
- Global audience (CDN benefits)
- Want auto-scaling
- Professional deployment

---

### Scenario 6: Prod - Fully Serverless

**Architecture:**
```
Internet
  ‚Üì
Vercel (Next.js + API routes)
  ‚Üì
Supabase Cloud (database + auth + storage)
  ‚Üë
VPS (crawler only)
```

**Setup:**
```bash
# 1. Create Supabase project (same as Scenario 5)

# 2. Deploy to Vercel
vercel deploy

# In Vercel dashboard ‚Üí Environment Variables:
NEXT_PUBLIC_SUPABASE_URL=https://xxxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJ...
SUPABASE_SERVICE_ROLE_KEY=eyJ...

# 3. Deploy crawler separately
# On small VPS:
docker run -d \
  -e SUPABASE_URL=https://xxxxx.supabase.co \
  -e SUPABASE_SERVICE_ROLE_KEY=eyJ... \
  -e CHAIN=dogecoin \
  ghcr.io/yourorg/nodes-crawler
```

**Benefits:**
- Auto-scaling web app
- Zero ops for frontend
- Global edge network
- Automatic SSL

**Cost:**
- Vercel Pro: $20/mo
- Supabase Pro: $25/mo
- Small VPS (crawler): $6/mo
- Total: ~$51/mo

**When to use:**
- Large network (10K+ nodes)
- Global audience
- Want zero-ops frontend
- Budget allows

---

## üîÑ Migration Paths

### Docker ‚Üí Cloud

```bash
# 1. Export database
docker exec atlasp2p-db pg_dump -U postgres > backup.sql

# 2. Create Supabase project
supabase projects create nodes

# 3. Import
cat backup.sql | psql "postgresql://postgres:PASSWORD@db.xxxxx.supabase.co:5432/postgres"

# 4. Switch environment
cp .env.cloud.example .env
# Edit with credentials

# 5. Stop Docker, start cloud
make docker-down
make cloud-dev
```

### Cloud ‚Üí Docker

```bash
# 1. Export from Supabase
supabase db dump > backup.sql

# 2. Switch environment
cp .env.docker.example .env

# 3. Start Docker
make docker-dev

# 4. Import (optional)
cat backup.sql | docker exec -i atlasp2p-db psql -U postgres
```

### Dev ‚Üí Production

**Docker to Docker:**
```bash
# Same .env, different target
make docker-dev   # Development
make prod-docker  # Production (adds Caddy + SSL)
```

**Cloud to Cloud:**
```bash
# Same Supabase project, different target
make cloud-dev    # Development
make prod-cloud   # Production (adds Caddy + SSL)
```

---

## üß™ Testing Scenarios

### Minimal Test (No Docker)

```bash
pnpm install
pnpm build
pnpm test
```

### Full Integration Test

```bash
make docker-dev
sleep 30  # Wait for services

# Test API
curl http://localhost:4000/api/stats

# Test database
docker exec atlasp2p-db psql -U postgres -c "SELECT COUNT(*) FROM nodes;"

# Test web
curl http://localhost:4000 | grep "Nodes Map"
```

---

## üìã Decision Tree

**Choose your deployment:**

```
Start
  ‚Üì
Is this for development?
‚îú‚îÄ Yes ‚Üí Do you want managed DB?
‚îÇ  ‚îú‚îÄ Yes ‚Üí Scenario 2 (Cloud Dev)
‚îÇ  ‚îî‚îÄ No  ‚Üí Scenario 1 (Docker Dev)
‚îÇ
‚îî‚îÄ No (Production) ‚Üí What's your budget?
   ‚îú‚îÄ <$30/mo  ‚Üí Scenario 4 (Self-Hosted)
   ‚îú‚îÄ $30-50/mo ‚Üí Scenario 5 (Hybrid Cloud)
   ‚îî‚îÄ >$50/mo  ‚Üí Scenario 6 (Serverless)
```

---

## üéØ Recommendations

### For Forks

**Start with:** Scenario 1 (Docker Dev)
- Easiest setup
- No external dependencies
- Learn the system

**Move to:** Scenario 2 (Cloud Dev)
- Test cloud features
- Prepare for production

**Deploy as:** Scenario 5 (Hybrid Cloud)
- Best balance of cost/features
- Scalable for growth

### For Contributors

**Use:** Scenario 3 (Bare Metal)
- Fastest iteration
- Frontend hot reload
- Easy debugging

### For Production

**Small networks (<1K nodes):** Scenario 4 (Self-Hosted)
**Medium networks (1-10K):** Scenario 5 (Hybrid Cloud)
**Large networks (>10K):** Scenario 6 (Serverless)

---

## ‚öôÔ∏è Configuration Comparison

| Variable | Docker Dev | Cloud Dev | Prod Docker | Prod Cloud |
|----------|------------|-----------|-------------|------------|
| `NEXT_PUBLIC_SUPABASE_URL` | localhost:4020 | *.supabase.co | localhost:4020 | *.supabase.co |
| `SUPABASE_INTERNAL_URL` | kong:8000 | *.supabase.co | kong:8000 | *.supabase.co |
| `DOMAIN` | - | - | Required | Required |
| `ACME_EMAIL` | - | - | Required | Required |
| `SMTP_HOST` | inbucket | SMTP server | SMTP server | SMTP server |
| `GOTRUE_MAILER_AUTOCONFIRM` | true | false | false | false |

---

## üîß Troubleshooting by Scenario

### Docker Dev: "Kong unhealthy"

```bash
make logs-auth   # Check auth/Kong logs
make restart     # Restart all services
```

### Cloud Dev: "Unauthorized"

```bash
# Check keys in .env
grep SUPABASE .env

# Test connection
curl https://xxxxx.supabase.co/rest/v1/ \
  -H "apikey: YOUR_ANON_KEY"
```

### Prod: "SSL failed"

```bash
# Check DNS
dig nodes.yourchain.com

# Check Caddy logs
make prod-logs

# Verify ACME_EMAIL
grep ACME_EMAIL .env
```

---

**Choose your scenario and follow the guide!** Each has detailed instructions in the respective documentation files.
